{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree classifier for classifying trafficking vs non-trafficking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to install\n",
    "- graphviz\n",
    "- sklearn\n",
    "- pydotplus\n",
    "- mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installs pydotplus for plotting of datatrees, since its not provided w default session. also installing graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pydotplus\n",
    "#!pip3 install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load requisite libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1d2120fc69ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miris_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, plot_confusion_matrix, plot_roc_curve\n",
    "\n",
    "from mlxtend.data import iris_data\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import os\n",
    "import math\n",
    "from math import floor, ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuff for plotting trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six import StringIO\n",
    "#from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDT(dtree,featureNames = None,classNames=None):\n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(dtree, \n",
    "                    out_file=dot_data,  \n",
    "                    feature_names = featureNames,\n",
    "                    class_names =  classNames,\n",
    "                    filled=True, \n",
    "                    rounded=True,\n",
    "                    special_characters=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "    l=Image(graph.create_png())\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestAccuracy(clf,X_test,y_test, display=False):\n",
    "    \n",
    "    y_pred  = clf.predict( X_test.values)  \n",
    "    results = ( y_test.values[:,0]==y_pred )\n",
    "\n",
    "    if display:\n",
    "        nEntries, dummy = X_test.shape\n",
    "        for i in range(nEntries):\n",
    "            print(X_test.iloc[i])\n",
    "            print(\"Class=%s Prediction %s %s\\n\"%(y_test.values[i,0],y_pred[i],results[i]) )\n",
    "        #print(\"prediction\",results)\n",
    "\n",
    "    # accuracy\n",
    "    nTrue = np.sum( results )\n",
    "    nTot = np.float( np.shape( results)[0] )\n",
    "    accuracy = nTrue/nTot\n",
    "    print(\"Overall accuracy \",accuracy)\n",
    "\n",
    "def TestAccuracySingle(clf,X_test,Y_test,idx=0):\n",
    "    \n",
    "    print(X_test.iloc[idx])\n",
    "    result = clf.predict( [X_test.values[idx,:]])\n",
    "    print(\"prediction\",result)\n",
    "    #print(Y_test.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TestAccuracy(clf_entropy,X_test,Y_test,display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with PAS data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('/Users/drkal/Desktop/professional/peter-lab/herg-project/machine-learning/my-work/dt/pas-md-trafficking-prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use \"comment = '#'\" for ignoring the commented out rows in pandas data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataFile = \"features-latest-sets1n2.txt\"\n",
    "\n",
    "df = pd.read_csv(dataFile, sep=\"\\s+\", comment='#')\n",
    "\n",
    "#df = pd.read_csv(\"data/cereal.csv\", skiprows = 1)\n",
    "#df.columns = df.iloc[0]\n",
    "#df=df.drop(df.index[0])\n",
    "#print(df.head(5))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['decimal_place_2'] = df['decimal_place_2'].round(2)\n",
    "df['HELIX'] = df['HELIX'].round(2)\n",
    "df['TURNS'] = df['TURNS'].round(2)\n",
    "df['COILS'] = df['COILS'].round(2)\n",
    "df['THREE-TEN'] = df['THREE-TEN'].round(2)\n",
    "df['BETA'] = df['BETA'].round(2)\n",
    "df['RMSD'] = df['RMSD'].round(2)\n",
    "df['HBONDS'] = df['HBONDS'].round()\n",
    "df['SASA'] = df['SASA'].round()\n",
    "df['WATERS'] = df['WATERS'].round()\n",
    "df['FOLDX'] = df['FOLDX'].round(2)\n",
    "df['CONSERVATION'] = df['CONSERVATION'].round(2)\n",
    "df['HYDROPHOBICITY'] = df['HYDROPHOBICITY'].round(2)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read a rmsf file to a pandas data frame\n",
    "rmsfile = \"/Users/drkal/Desktop/professional/peter-lab/herg-project/machine-learning/herg-features/rmsf/rmsf-matrix.txt\"\n",
    "dfrmsf = pd.read_csv(rmsfile, sep=\"\\s+\", comment='#')\n",
    "dfrmsf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract a subset of rows from rmsf file\n",
    "dfrmsf_sub = dfrmsf.loc[89:94,] # actual residues in the sequence 115 to 120 \n",
    "dfrmsf_sub2 = dfrmsf.loc[10:15,]# actual residues in the sequence 36 to 41\n",
    "dfrmsf_sub3 = dfrmsf.loc[61:66,]# actual residues in the sequence 87 to 92\n",
    "dfrmsf_sub4 = dfrmsf.loc[47:52,]# actual residues in the sequence 73 to 78\n",
    "\n",
    "#calculate the mean of the rows 89 to 94 for each variant\n",
    "dfrmsf_sub_mean = dfrmsf_sub.mean().round(2)\n",
    "dfrmsf_sub2_mean = dfrmsf_sub2.mean().round(2)\n",
    "dfrmsf_sub3_mean = dfrmsf_sub3.mean().round(2)\n",
    "dfrmsf_sub4_mean = dfrmsf_sub4.mean().round(2)\n",
    "\n",
    "#dfrmsf_sub_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrmsf_sub_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the mean of rows 89 to 94 to a file\n",
    "dfrmsf_sub_mean.to_csv('/Users/drkal/Desktop/professional/peter-lab/herg-project/machine-learning/herg-features/rmsf/rmsf_sub.txt', sep='\\t', header=[\"RMSF115TO120\"])\n",
    "dfrmsf_sub2_mean.to_csv('/Users/drkal/Desktop/professional/peter-lab/herg-project/machine-learning/herg-features/rmsf/rmsf_sub2.txt', sep='\\t', header=[\"RMSF36TO41\"])\n",
    "dfrmsf_sub3_mean.to_csv('/Users/drkal/Desktop/professional/peter-lab/herg-project/machine-learning/herg-features/rmsf/rmsf_sub3.txt', sep='\\t', header=[\"RMSF87TO92\"])\n",
    "dfrmsf_sub4_mean.to_csv('/Users/drkal/Desktop/professional/peter-lab/herg-project/machine-learning/herg-features/rmsf/rmsf_sub4.txt', sep='\\t', header=[\"RMSF73TO78\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrmsf_sub_mean.columns=['RMSF115TO120']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('/Users/drkal/Desktop/professional/peter-lab/herg-project/machine-learning/herg-features/rmsf/rmsf_sub.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[\"HELIX\",\"TURNS\",\"COILS\",\"THREE-TEN\",\"BETA\",\"RMSD\",\"HBONDS\",\"SASA\",\"WATERS\",\"FOLDX\",\"CONSERVATION\",\"HYDROPHOBICITY\"]\n",
    "#features1=[\"HBONDS\",\"WATERS\",\"FOLDX\", \"TURNS\",\"CONSERVATION\"]\n",
    "\n",
    "output = [\"TRAFFICKING\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df[features1]\n",
    "X = df[features]\n",
    "Y = df[output]\n",
    "#X.head()\n",
    "#Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test =\\\n",
    "  train_test_split( X, Y, train_size=0.7, test_size=0.3, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> Data looks very unbalanced</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### upsample the minority class, which is benign (class = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate our traning data back together\n",
    "#C = pd.concat([X_train, Y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate minority and majority classes\n",
    "#group = C.groupby('CLASS')\n",
    "#benign=list(group)[0][1]\n",
    "#pathogenic=list(group)[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsample minority\n",
    "#benign_upsampled = resample(benign,\n",
    "#                            replace=True, #sample with replacement\n",
    "#                            n_samples=len(pathogenic), #match number in majority class\n",
    "#                            random_state=100 #reproduce results\n",
    "#                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine majority and upsampled minority\n",
    "#upsampled = pd.concat([pathogenic, benign_upsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using class_weight=\"balanced\" to reweight classes based on class frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the classifier and fitting it\n",
    "clf_entropy = DecisionTreeClassifier(\n",
    "  criterion = \"entropy\",\n",
    "  #class_weight=\"balanced\",\n",
    "  random_state=50, #set random number seed  \n",
    "  max_depth=None,\n",
    "    max_features=4,\n",
    "    min_samples_leaf=1) #min of samples needed at a node for it to split further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the classifier with resampled data\n",
    "#X_train=pd.DataFrame(upsampled, columns=[\"RMSD\", \"HBONDS\", \"WATERS\"])\n",
    "#X_train=pd.DataFrame(upsampled, columns=[\"RMSD\"])\n",
    "#Y_train=pd.DataFrame(upsampled, columns=[\"CLASS\"])\n",
    "\n",
    "model=clf_entropy.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print training accuracy\n",
    "print(\"Training sample accuracy\")\n",
    "TestAccuracy(clf_entropy,X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#classNames=np.array(['0', '1']) # need to verify, but I think this is correct\n",
    "#classNames=np.array(['benign', 'pathogenic']) # need to verify, but I think this is correct\n",
    "classNames=np.array(['non-trafficking', 'trafficking']) # need to verify, but I think this is correct\n",
    "plotDT(clf_entropy,featureNames=features, classNames=classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('dt_tree_allfeatures.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TestAccuracy(clf_entropy,X_test,Y_test, display=True)\n",
    "print('Test Accuracy')\n",
    "TestAccuracy(clf_entropy,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf_entropy.predict(X_test.values)\n",
    "\n",
    "#model = lr.fit(X,y)\n",
    "#probas_ = model.predict_log_proba(X)\n",
    "#y_predict_proba = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print overall classification metrics\n",
    "print(classification_report(Y_test, y_predict, target_names=classNames))\n",
    "plt.savefig('report.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(confusion_matrix(Y_test, y_predict))\n",
    "plot_confusion_matrix(clf_entropy, X_test, Y_test)\n",
    "plt.savefig('dt_cm_allfeatures.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_predict = clf_entropy.predict(X_test)\n",
    "\n",
    "#Y_test=np.array(Y_test)\n",
    "#Y_test2=Y_test.reshape(23,)\n",
    "\n",
    "#new_ypredict = [int(y) for y in y_predict]\n",
    "#new_Y_test = [int(f) for f in Y_test2]\n",
    "\n",
    "#fpr, tpr, thresholds = metrics.roc_curve(new_Y_test, new_ypredict, pos_label=1)\n",
    "\n",
    "#print (\"FPR\", fpr*100)\n",
    "#print (\"TPR\", tpr*100)\n",
    "#print (\"thresholds\", thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve\n",
    "#metrics.roc_curve(clf_entropy, X_test, Y_test)\n",
    "metrics.plot_roc_curve(clf_entropy, X_test, Y_test)\n",
    "plt.savefig('dt_roc_allfeatures.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print feature importance\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh', color=\"red\").grid(False)\n",
    "plt.title('Feature Importances - All Features (DT)')\n",
    "#plt.legend(bbox_to_anchor=(1,1))\n",
    "plt.savefig('dt_fi_allfeatures.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model and visualizer\n",
    "#from yellowbrick.model_selection import FeatureImportances\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate model and visualizer\n",
    "#model = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "#visualizer = FeatureImportances(model)\n",
    "\n",
    "# Fit and display visualizer\n",
    "#visualizer.fit(X, Y)\n",
    "#visualizer.show();\n",
    "#plt.savefig('dt_fi_allfeatures2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting probabilities rather than hard predicitons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate data for ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEX = df[['HELIX']]\n",
    "B = df[[\"BETA\"]]\n",
    "T = df[[\"TURNS\"]]\n",
    "C = df[[\"COILS\"]]\n",
    "TT = df[[\"THREE-TEN\"]]\n",
    "R = df[[\"RMSD\"]]\n",
    "W = df[[\"WATERS\"]]\n",
    "H = df[[\"HBONDS\"]]\n",
    "S = df[[\"SASA\"]]\n",
    "F=df[['FOLDX']]\n",
    "CO=df[[\"CONSERVATION\"]]\n",
    "HY=df[[\"HYDROPHOBICITY\"]]\n",
    "\n",
    "Y = df[\"TRAFFICKING\"]\n",
    "#X = df[features]\n",
    "\n",
    "#extracting metrics for whole model\n",
    "y_predict = clf_entropy.fit(X_train, Y_train).predict_proba(X_test)\n",
    "#y_predict = clf_entropy.fit(X_train, Y_train).decisions(X_test)\n",
    "fpr, tpr, thr = metrics.roc_curve(Y_test, y_predict[:,1], drop_intermediate=False)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "#redifined the classifier for one feature\n",
    "clf2_dt = DecisionTreeClassifier(criterion = \"entropy\",random_state=50,max_depth=None, min_samples_leaf=1)\n",
    "\n",
    "#helicity\n",
    "#split\n",
    "HEX_train, HEX_test, HEY_train, HEY_test = train_test_split(HEX, Y, train_size=0.7, test_size=0.3, random_state=50)\n",
    "#train\n",
    "#modelHE=clf2_dt.fit(HEX_train, HEY_train.values.ravel())\n",
    "#train\n",
    "#HEY_predict = clf2_dt.predict(HEX_test.values)\n",
    "HEY_predict = clf2_dt.fit(HEX_train, HEY_train.values.ravel()).predict_proba(HEX_test.values)\n",
    "f_helix, t_helix, th_helix = metrics.roc_curve(HEY_test, HEY_predict[:,1], pos_label=1, drop_intermediate=False)\n",
    "helix_auc = metrics.auc(f_helix, t_helix)\n",
    "\n",
    "#beta\n",
    "bx_train, bx_test, by_train, by_test = train_test_split(B, Y, train_size=0.7, test_size=0.3, random_state=50)\n",
    "#modelB=clf2_dt.fit(bx_train, by_train.values.ravel())\n",
    "#by_predict = clf2_dt.predict(bx_test.values)\n",
    "by_predict = clf2_dt.fit(bx_train, by_train).predict_proba(bx_test)\n",
    "f_beta, t_beta, th_beta = metrics.roc_curve(by_test, by_predict[:,1], pos_label=1, drop_intermediate=False)\n",
    "beta_auc = metrics.auc(f_beta, t_beta)\n",
    "\n",
    "#coil\n",
    "cx_train, cx_test, cy_train, cy_test = train_test_split(C, Y, train_size=0.7, test_size=0.3, random_state=50)\n",
    "#modelC=clf2_dt.fit(cx_train, cy_train.values.ravel())\n",
    "#cy_predict = clf2_dt.predict(cx_test.values)\n",
    "cy_predict = clf2_dt.fit(cx_train, cy_train).predict_proba(cx_test)\n",
    "f_coil, t_coil, th_coil = metrics.roc_curve(cy_test, cy_predict[:,1], pos_label=1, drop_intermediate=False)\n",
    "coil_auc = metrics.auc(f_coil, t_coil)\n",
    "\n",
    "#3-10\n",
    "ttx_train, ttx_test, tty_train, tty_test = train_test_split(TT, Y, train_size=0.7, test_size=0.3, random_state=50)\n",
    "#modelTT=clf2_dt.fit(ttx_train, tty_train.values.ravel())\n",
    "#tty_predict = clf2_dt.predict(ttx_test.values)\n",
    "tty_predict = clf2_dt.fit(ttx_train, tty_train).predict_proba(ttx_test)\n",
    "f_tten, t_tten, th_tten = metrics.roc_curve(tty_test, tty_predict[:,1], pos_label=1, drop_intermediate=False)\n",
    "tten_auc = metrics.auc(f_tten, t_tten)\n",
    "\n",
    "#rmsd\n",
    "#extract metrics for rmsd. f_rmsd = false positive rate, t_rmsd=true positive rate, th_rmsd=threshold values\n",
    "rx_train, rx_test, ry_train, ry_test = train_test_split(R, Y, train_size=0.7, test_size=0.3, random_state=50)\n",
    "#modelR=clf2_dt.fit(rx_train, ry_train.values.ravel())\n",
    "#ry_predict = clf2_dt.predict(rx_test.values)\n",
    "ry_predict = clf2_dt.fit(rx_train, ry_train).predict_proba(rx_test)\n",
    "f_rmsd, t_rmsd, th_rmsd = metrics.roc_curve(ry_test, ry_predict[:,1], pos_label=1, drop_intermediate=False)\n",
    "rmsd_auc = metrics.auc(f_rmsd, t_rmsd)\n",
    "\n",
    "#extract metrics for sasa\n",
    "sx_train, sx_test, sy_train, sy_test = train_test_split(S, Y, train_size=0.7, test_size=0.3, random_state=50)\n",
    "#modelS=clf2_dt.fit(sx_train, sy_train.values.ravel())\n",
    "#sy_predict = clf2_dt.predict(sx_test.values)\n",
    "sy_predict = clf2_dt.fit(sx_train, sy_train).predict_proba(sx_test)\n",
    "f_sasa, t_sasa, th_sasa = metrics.roc_curve(sy_test, sy_predict[:,1], pos_label=1, drop_intermediate=False)\n",
    "sasa_auc = metrics.auc(f_sasa, t_sasa)\n",
    "\n",
    "#hbonds\n",
    "#extract metrics for hbonds\n",
    "hx_train, hx_test, hy_train, hy_test = train_test_split(H, Y, train_size=0.7, test_size=0.3, random_state=50)\n",
    "#modelH=clf2_dt.fit(hx_train, hy_train.values.ravel())\n",
    "#hy_predict = clf2_dt.predict(hx_test.values)\n",
    "hy_predict = clf2_dt.fit(hx_train, hy_train).predict_proba(hx_test)\n",
    "f_hbonds, t_hbonds, th_hbonds = metrics.roc_curve(hy_test, hy_predict[:,1], pos_label=1, drop_intermediate=False)\n",
    "hbonds_auc = metrics.auc(f_hbonds, t_hbonds)\n",
    "\n",
    "#water\n",
    "#extract metrics for water\n",
    "wx_train, wx_test, wy_train, wy_test = train_test_split(W, Y, train_size=0.7, test_size=0.3, random_state=50)\n",
    "#modelW=clf2_dt.fit(wx_train, wy_train.values.ravel())\n",
    "#wy_predict = clf2_dt.predict(wx_test.values)\n",
    "wy_predict = clf2_dt.fit(wx_train, wy_train).predict_proba(wx_test)\n",
    "f_water, t_water, th_water = metrics.roc_curve(wy_test, wy_predict[:,1], pos_label=1)\n",
    "water_auc = metrics.auc(f_water, t_water)\n",
    "\n",
    "#turns\n",
    "tx_train, tx_test, ty_train, ty_test = train_test_split(T, Y, train_size=0.7, test_size=0.3, random_state=50)\n",
    "modelT=clf2_dt.fit(tx_train, ty_train.values.ravel())\n",
    "#ty_predict = clf2_dt.predict(tx_test.values)\n",
    "ty_predict = clf2_dt.fit(tx_train, ty_train).predict_proba(tx_test)\n",
    "f_turns, t_turns, th_turns = metrics.roc_curve(ty_test, ty_predict[:,1], pos_label=1, drop_intermediate=False)\n",
    "turns_auc = metrics.auc(f_turns, t_turns)\n",
    "\n",
    "\n",
    "\n",
    "#foldx\n",
    "fx_train, fx_test, fy_train, fy_test = train_test_split(F, Y, train_size=0.7, test_size=0.3, random_state=50)\n",
    "#modelF=clf2_dt.fit(fx_train, fy_train.values.ravel())\n",
    "#fy_predict = clf2_dt.predict(fx_test.values)\n",
    "fy_predict = clf2_dt.fit(fx_train, fy_train).predict_proba(fx_test)\n",
    "f_foldx, t_foldx, th_foldx = metrics.roc_curve(fy_test, fy_predict[:,1], pos_label=1, drop_intermediate=False)\n",
    "foldx_auc = metrics.auc(f_foldx, t_foldx)\n",
    "\n",
    "#conservation\n",
    "cox_train, cox_test, coy_train, coy_test = train_test_split(CO, Y, train_size=0.7, test_size=0.3, random_state=50)\n",
    "#modelCO=clf2_dt.fit(cox_train, coy_train.values.ravel())\n",
    "#coy_predict = clf2_dt.predict(cox_test)\n",
    "coy_score = clf2_dt.fit(cox_train, coy_train).predict_proba(cox_test)\n",
    "f_cons, t_cons, th_cons = metrics.roc_curve(coy_test, coy_score[:,1], pos_label=1, drop_intermediate=False)\n",
    "cons_auc = metrics.auc(f_cons, t_cons)\n",
    "\n",
    "#hydrophobicity\n",
    "hyx_train, hyx_test, hyy_train, hyy_test = train_test_split(HY, Y, train_size=0.7, test_size=0.3, random_state=50)\n",
    "#modelHY=clf2_dt.fit(hyx_train, hyy_train.values.ravel())\n",
    "#hyy_predict = clf2_dt.predict(hyx_test.values)\n",
    "#hyy_predict = clf2_dt.decision_function(hyx_test.values)\n",
    "hyy_predict = clf2_dt.fit(hyx_train, hyy_train).predict_proba(hyx_test)\n",
    "#f_hydr, t_hydr, th_hydr = metrics.roc_curve(hyy_test, hyy_predict)\n",
    "f_hydr, t_hydr, th_hydr = metrics.roc_curve(hyy_test, hyy_predict[:,1], drop_intermediate=False)\n",
    "hydr_auc = metrics.auc(f_hydr, t_hydr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot the roc curves of rmsd, waters and hbonds. auc is area under the curve\n",
    "#plot_roc_curve(clf_entropy, X_test, Y_test)\n",
    "plt.plot (fpr, tpr, color='cyan', label=\"DT Classifier(AUC=%0.2f)\"% auc)\n",
    "plt.plot (f_tten, t_tten, label=\"3-10 (AUC=%0.2f)\"% tten_auc)\n",
    "plt.plot (f_hydr, t_hydr, color='black', label=\"Hydrophobicity (AUC=%0.2f)\"% hydr_auc)\n",
    "plt.plot(f_helix, t_helix, label=\"HELIX(AUC=%0.2f)\"% helix_auc)\n",
    "plt.plot (f_beta, t_beta, label=\"BETA (AUC=%0.2f)\"% beta_auc)\n",
    "plt.plot (f_sasa, t_sasa, label=\"SASA (AUC=%0.2f)\"% sasa_auc)\n",
    "plt.plot (f_water, t_water, label=\"Waters (AUC=%0.2f)\"% water_auc)\n",
    "plt.plot (f_coil, t_coil, label=\"Coils (AUC=%0.2f)\"% coil_auc)\n",
    "plt.plot (f_turns, t_turns, label=\"TURNS (AUC=%0.2f)\"% turns_auc)\n",
    "plt.plot (f_foldx, t_foldx, color='magenta', label=\"FoldX (AUC=%0.2f)\"% foldx_auc)\n",
    "plt.plot(f_rmsd, t_rmsd, label=\"RMSD(AUC=%0.2f)\"% rmsd_auc)\n",
    "plt.plot (f_hbonds, t_hbonds, label=\"H-Bonds (AUC=%0.2f)\"% hbonds_auc)\n",
    "plt.plot (f_cons, t_cons, color='blue', label=\"Conservation (AUC=%0.2f)\"% cons_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--', label='Random')\n",
    "plt.grid(False)\n",
    "plt.title('ROC curve-All features (DT)')\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "#plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1,1), loc='upper left')\n",
    "plt.savefig('dt_roc_allfeatures.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###plot just the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot (fpr, tpr, color='black', label=\"DT(AUC=%0.2f)\"% auc)\n",
    "#plt.plot([0, 1], [0, 1], color='navy', linestyle='--', label='Random')\n",
    "#plt.title('ROC curve-All features (DT)')\n",
    "#plt.xlabel(\"FPR\")\n",
    "#plt.ylabel(\"TPR\")\n",
    "#plt.legend(loc=\"lower right\")\n",
    "\n",
    "##plt.legend(bbox_to_anchor=(1,0.9), loc='upper left')\n",
    "#plt.savefig('dt_roc_allfeatures_justmodel.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import math\n",
    "#from math import floor, ceil\n",
    "\n",
    "#print (\"FPR-RMSD\", f_rmsd)\n",
    "#print (\"TPR-RMSD\", t_rmsd)\n",
    "#print (\"thresholds-RMSD\", th_rmsd)\n",
    "\n",
    "#print (\"FPR-WATERS\", f_water)\n",
    "#print (\"TPR-WATERS\", t_water)\n",
    "#print (\"thresholds-WATERS\", th_water)\n",
    "\n",
    "#print (\"FPR-HBONDS\", f_hbonds)\n",
    "#print (\"TPR-HBONDS\", t_hbonds)\n",
    "#print (\"thresholds-HBONDS\", th_hbonds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_fpr = np.array([0. , 0.5, 1. ])\n",
    "bio_tpr = np.array([0., 1., 1.])\n",
    "bio_auc = 0.75\n",
    "\n",
    "md_fpr = np.array([0.        , 0.41666667, 1.        ])\n",
    "md_tpr = np.array([0.        , 0.72727273, 1.        ])\n",
    "md_auc = 0.6553030303030303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_roc_curve(clf_rf, X_test, Y_test, color='red', label=\"All(AUC=%0.2f)\")\n",
    "plt.plot (fpr, tpr, color='red', label=\"All(AUC=%0.2f)\"%auc)\n",
    "plt.plot (bio_fpr, bio_tpr, color='blue', label=\"Bioinformatics(AUC=%0.2f)\"%bio_auc)\n",
    "plt.plot (md_fpr, md_tpr, color='green', label=\"MD(AUC=%0.2f)\"%md_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--', label='Random')\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title('ROC curve (DT)')\n",
    "\n",
    "plt.savefig('dt_roc_all_models.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
